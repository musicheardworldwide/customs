[{"id":"brain","user_id":"d5f14370-de3d-47d6-b47d-3493ec9e2df2","name":"brain","type":"filter","content":"\"\"\"\ntitle: Neural Recall\nauthor: jbuch\nauthor_url: https://forms.gle/rYoVzRSMeM2azt1F8\nfunding_url: https://tiptopjar.com/jbuch\ndescription: Neural Recall is an advanced memory augmentation system designed to enhance the contextual awareness\nof large language models. Inspired by the intricate workings of neural networks, this plugin seamlessly\nintegrates with Open WebUI, providing a persistent, structured memory for your AI interactions.\nNeural Recall intelligently extracts key facts from conversations, filtering out transient noise\nand focusing on persistent user data, allowing your LLM to build a richer understanding of the user\nover time, leading to more personalized and contextually relevant responses.\nversion: 1.2.0\nlicense: MIT\n\"\"\"\n\nimport json\nimport traceback\nfrom datetime import datetime\nfrom typing import Any, Awaitable, Callable, Dict, List, Literal, Optional, Union, Set\nimport logging\nimport re\nimport asyncio\nimport pytz\nimport difflib\nfrom difflib import SequenceMatcher\n\nimport aiohttp\nfrom aiohttp import ClientError, ClientSession\nfrom fastapi.requests import Request\nfrom pydantic import BaseModel, Field, model_validator\n\n# Updated imports for OpenWebUI 0.5+\nfrom open_webui.routers.memories import (\n    add_memory,\n    AddMemoryForm,\n    query_memory,\n    QueryMemoryForm,\n    delete_memory_by_id,\n    Memories,\n)\nfrom open_webui.models.users import Users\nfrom open_webui.main import app as webui_app\n\n# Set up logging\nlogger = logging.getLogger(\"IntelligentMemoryManager\")\nhandler = logging.StreamHandler()\nformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\nlogger.setLevel(logging.INFO)\n\n\nclass MemoryOperation(BaseModel):\n    \"\"\"Model for memory operations\"\"\"\n\n    operation: Literal[\"NEW\", \"UPDATE\", \"DELETE\"]\n    id: Optional[str] = None\n    content: Optional[str] = None\n    tags: List[str] = []\n\n\nclass Filter:\n    class Valves(BaseModel):\n        \"\"\"Configuration valves for the filter\"\"\"\n\n        # API configuration\n        api_provider: Literal[\"Ollama API\", \"OpenAI API\"] = Field(\n            default=\"Ollama API\",\n            description=\"Choose LLM API provider for memory processing\",\n        )\n\n        # Ollama settings\n        ollama_api_url: str = Field(\n            default=\"https://api.musicheardworldwide.com\",\n            description=\"Ollama API URL\",\n        )\n        ollama_model: str = Field(\n            default=\"llama3.2:3b-instruct-q8_0\",\n            description=\"Ollama model to use for memory processing\",\n        )\n\n        # OpenAI settings\n        openai_api_url: str = Field(\n            default=\"https://api.groq.com/openai/v1\", description=\"OpenAI API URL\"\n        )\n        openai_api_key: str = Field(default=\"\", description=\"OpenAI API Key\")\n        openai_model: str = Field(\n            default=\"sin\",\n            description=\"OpenAI model to use for memory processing\",\n        )\n\n        # Memory processing settings\n        related_memories_n: int = Field(\n            default=10,\n            description=\"Number of related memories to consider\",\n        )\n        relevance_threshold: float = Field(\n            default=0.6,\n            description=\"Minimum relevance score (0-1) for memories to be considered relevant\",\n        )\n        memory_threshold: float = Field(\n            default=0.7,\n            description=\"Threshold for similarity when comparing memories (0-1)\",\n        )\n\n        # Deduplicate identical memories\n        deduplicate_memories: bool = Field(\n            default=True,\n            description=\"Prevent storing duplicate or very similar memories\",\n        )\n\n        similarity_threshold: float = Field(\n            default=0.85, description=\"Threshold for detecting similar memories (0-1)\"\n        )\n\n        # Time settings\n        timezone: str = Field(\n            default=\"UTC\",\n            description=\"Timezone for date/time processing (e.g., 'America/New_York', 'Europe/London')\",\n        )\n\n        # UI settings\n        show_status: bool = Field(\n            default=True, description=\"Show memory operations status in chat\"\n        )\n        show_memories: bool = Field(\n            default=True, description=\"Show relevant memories in context\"\n        )\n        memory_format: Literal[\"bullet\", \"paragraph\", \"numbered\"] = Field(\n            default=\"bullet\", description=\"Format for displaying memories in context\"\n        )\n\n        # Memory categories\n        enable_identity_memories: bool = Field(\n            default=True,\n            description=\"Enable collecting Basic Identity information (age, gender, location, etc.)\",\n        )\n        enable_behavior_memories: bool = Field(\n            default=True,\n            description=\"Enable collecting Behavior information (interests, habits, etc.)\",\n        )\n        enable_preference_memories: bool = Field(\n            default=True,\n            description=\"Enable collecting Preference information (likes, dislikes, etc.)\",\n        )\n        enable_goal_memories: bool = Field(\n            default=True,\n            description=\"Enable collecting Goal information (aspirations, targets, etc.)\",\n        )\n        enable_relationship_memories: bool = Field(\n            default=True,\n            description=\"Enable collecting Relationship information (friends, family, etc.)\",\n        )\n        enable_possession_memories: bool = Field(\n            default=True,\n            description=\"Enable collecting Possession information (things owned or desired)\",\n        )\n\n        # Error handling\n        max_retries: int = Field(\n            default=2, description=\"Maximum number of retries for API calls\"\n        )\n\n        retry_delay: float = Field(\n            default=1.0, description=\"Delay between retries (seconds)\"\n        )\n\n        # System prompts\n        memory_identification_prompt: str = Field(\n            default=\"\"\"You are a memory manager for a language model. You process user messages to extract information worth remembering for future conversations.\n\nYour task is to identify facts about the user from the provided text and existing memories. Your ONLY output should be a JSON array of memory operations. Do not include any other text.\n\nEach memory operation should be one of:\n- NEW: Create a new memory.\n- UPDATE: Update an existing memory.\n- DELETE: Remove an existing memory.\n\nOutput format MUST be a valid JSON array containing objects with these fields:\n- operation: \"NEW\", \"UPDATE\", or \"DELETE\"\n- id: memory id (required for UPDATE and DELETE)\n- content: memory content (required for NEW and UPDATE)\n- tags: array of relevant tags from these categories: [\"identity\", \"behavior\", \"preference\", \"goal\", \"relationship\", \"possession\"]\n\nIMPORTANT: Your response must begin with a properly formatted JSON array like this:\n[{\"operation\": \"NEW\", \"content\": \"User likes coffee\", \"tags\": [\"preference\"]}]\n\nRules for memory content:\n- Include full context for understanding.\n- Tag memories appropriately for better retrieval.\n- Combine related information.\n- Avoid storing temporary or query-like information.\n- Include location, time, or date information when possible.\n- Add context about the memory.\n- If the user says \"tomorrow\", resolve it to a date.\n- If a date/time specific fact is mentioned, add the date/time to the memory.\n\nImportant information types:\n- Basic Identity (age, gender, location, job title, education level, etc.)\n- Behaviors (interests, habits, etc.)\n- Preferences (communication style, preferred language, etc.)\n- Goals (goals, targets, aspirations, etc.)\n- Relationships (personal and professional relationships)\n- Possessions (important items owned or desired)\n\nFor UPDATE and DELETE operations, the 'id' MUST exactly match an ID from 'Existing Memories'. Do NOT generate new IDs.\n\nIf the text contains no useful information to remember, return an empty array: []\"\"\",\n            description=\"System prompt for memory identification\",\n        )\n\n        memory_relevance_prompt: str = Field(\n            default=\"\"\"You are a memory retrieval assistant. Your task is to determine which memories are relevant to the current context of a conversation.\n\nGiven the current user message and a set of memories, rate each memory's relevance on a scale from 0 to 1, where:\n- 0 means completely irrelevant\n- 1 means highly relevant and directly applicable\n\nConsider:\n- Explicit mentions in the user message\n- Implicit connections to the current topic\n- Potential usefulness for answering questions\n- Recency and importance of the memory\n\nReturn your analysis as a JSON array with each memory's content, ID, and relevance score.\nExample: [{\"memory\": \"User likes coffee\", \"id\": \"123\", \"relevance\": 0.8}]\n\nYour output must be valid JSON only. No additional text.\"\"\",\n            description=\"System prompt for memory relevance assessment\",\n        )\n\n        memory_merge_prompt: str = Field(\n            default=\"\"\"You are a memory consolidation assistant. When given sets of memories, you merge similar or related memories while preserving all important information.\n\nRules for merging:\n1. If two memories contradict, keep the newer information\n2. Combine complementary information into a single comprehensive memory\n3. Maintain the most specific details when merging\n4. If two memories are distinct enough, keep them separate\n5. Remove duplicate memories\n\nReturn your result as a JSON array of strings, with each string being a merged memory.\nYour output must be valid JSON only. No additional text.\"\"\",\n            description=\"System prompt for merging memories\",\n        )\n\n    class UserValves(BaseModel):\n        enabled: bool = Field(\n            default=True, description=\"Enable or disable the memory function\"\n        )\n        show_status: bool = Field(\n            default=True, description=\"Show memory processing status updates\"\n        )\n        timezone: str = Field(\n            default=\"\",\n            description=\"User's timezone (overrides global setting if provided)\",\n        )\n\n    def __init__(self):\n        self.valves = self.Valves()\n        self.stored_memories = None\n        self._error_message = None\n        self._aiohttp_session = None\n\n        # Background tasks tracking\n        self._background_tasks = set()\n\n        # Model discovery results\n        self.available_ollama_models = []\n        self.available_openai_models = []\n\n        # Add current date awareness for prompts\n        self.current_date = datetime.now()\n        self.date_info = self._update_date_info()\n\n        # Schedule regular date updates\n        self._date_update_task = self._schedule_date_update()\n\n        # Schedule model discovery\n        self._model_discovery_task = self._schedule_model_discovery()\n\n    def _update_date_info(self):\n        \"\"\"Update the date information dictionary with current time\"\"\"\n        return {\n            \"iso_date\": self.current_date.strftime(\"%Y-%m-%d\"),\n            \"year\": self.current_date.year,\n            \"month\": self.current_date.strftime(\"%B\"),\n            \"day\": self.current_date.day,\n            \"weekday\": self.current_date.strftime(\"%A\"),\n            \"hour\": self.current_date.hour,\n            \"minute\": self.current_date.minute,\n            \"iso_time\": self.current_date.strftime(\"%H:%M:%S\"),\n        }\n\n    def _schedule_date_update(self):\n        \"\"\"Schedule a regular update of the date information\"\"\"\n\n        async def update_date_loop():\n            try:\n                while True:\n                    await asyncio.sleep(900)  # 15 minutes\n                    self.current_date = self.get_formatted_datetime()\n                    self.date_info = self._update_date_info()\n                    logger.debug(f\"Updated date information: {self.date_info}\")\n            except asyncio.CancelledError:\n                logger.debug(\"Date update task cancelled\")\n            except Exception as e:\n                logger.error(f\"Error in date update task: {e}\")\n\n        # Start the update loop in the background\n        task = asyncio.create_task(update_date_loop())\n        self._background_tasks.add(task)\n        task.add_done_callback(self._background_tasks.discard)\n        return task\n\n    def _schedule_model_discovery(self):\n        \"\"\"Schedule a regular update of available models\"\"\"\n\n        async def discover_models_loop():\n            try:\n                while True:\n                    try:\n                        # Discover models\n                        await self._discover_models()\n                        # Wait for 1 hour before checking again\n                        await asyncio.sleep(3600)\n                    except asyncio.CancelledError:\n                        raise\n                    except Exception as e:\n                        logger.error(f\"Error in model discovery: {e}\")\n                        await asyncio.sleep(300)  # Retry after 5 minutes on error\n            except asyncio.CancelledError:\n                logger.debug(\"Model discovery task cancelled\")\n\n        # Start the discovery loop in the background\n        task = asyncio.create_task(discover_models_loop())\n        self._background_tasks.add(task)\n        task.add_done_callback(self._background_tasks.discard)\n        return task\n\n    async def _discover_models(self):\n        \"\"\"Discover available models from open_webui.configured providers\"\"\"\n        logger.debug(\"Starting model discovery\")\n\n        # Create a session if needed\n        session = await self._get_aiohttp_session()\n\n        # Discover Ollama models\n        try:\n            ollama_url = f\"{self.valves.ollama_api_url.rstrip('/')}/api/tags\"\n            async with session.get(ollama_url) as response:\n                if response.status == 200:\n                    data = await response.json()\n                    if \"models\" in data:\n                        self.available_ollama_models = [\n                            model[\"name\"] for model in data[\"models\"]\n                        ]\n                    logger.debug(\n                        f\"Discovered {len(self.available_ollama_models)} Ollama models\"\n                    )\n        except Exception as e:\n            logger.warning(f\"Error discovering Ollama models: {e}\")\n            self.available_ollama_models = []\n\n        # Discover OpenAI models if API key is set\n        if self.valves.openai_api_key:\n            try:\n                openai_url = f\"{self.valves.openai_api_url.rstrip('/')}/v1/models\"\n                headers = {\"Authorization\": f\"Bearer {self.valves.openai_api_key}\"}\n\n                async with session.get(openai_url, headers=headers) as response:\n                    if response.status == 200:\n                        data = await response.json()\n                        if \"data\" in data:\n                            self.available_openai_models = [\n                                model[\"id\"] for model in data[\"data\"]\n                            ]\n                        logger.debug(\n                            f\"Discovered {len(self.available_openai_models)} OpenAI models\"\n                        )\n            except Exception as e:\n                logger.warning(f\"Error discovering OpenAI models: {e}\")\n                self.available_openai_models = []\n\n    def get_formatted_datetime(self, user_timezone=None):\n        \"\"\"\n        Get properly formatted datetime with timezone awareness\n\n        Args:\n            user_timezone: Optional timezone string to override the default\n\n        Returns:\n            Timezone-aware datetime object\n        \"\"\"\n        timezone_str = user_timezone or self.valves.timezone or \"UTC\"\n\n        # Handle common timezone abbreviations\n        timezone_mapping = {\n            \"PST\": \"America/Los_Angeles\",\n            \"PDT\": \"America/Los_Angeles\",\n            \"EST\": \"America/New_York\",\n            \"EDT\": \"America/New_York\",\n            \"CST\": \"America/Chicago\",\n            \"CDT\": \"America/Chicago\",\n            \"MST\": \"America/Denver\",\n            \"MDT\": \"America/Denver\",\n            \"GMT\": \"UTC\",\n            \"UTC\": \"UTC\",\n        }\n\n        # Try to map abbreviation to IANA timezone name\n        if timezone_str in timezone_mapping:\n            timezone_str = timezone_mapping[timezone_str]\n\n        try:\n            utc_now = datetime.utcnow()\n            local_tz = pytz.timezone(timezone_str)\n            local_now = utc_now.replace(tzinfo=pytz.utc).astimezone(local_tz)\n            return local_now\n        except pytz.exceptions.UnknownTimeZoneError:\n            logger.warning(f\"Invalid timezone: {timezone_str}, falling back to UTC\")\n            return datetime.utcnow().replace(tzinfo=pytz.utc)\n\n    async def _get_aiohttp_session(self) -> aiohttp.ClientSession:\n        \"\"\"Get or create an aiohttp session\"\"\"\n        if self._aiohttp_session is None or self._aiohttp_session.closed:\n            self._aiohttp_session = aiohttp.ClientSession(\n                timeout=aiohttp.ClientTimeout(total=30)  # 30 second timeout\n            )\n        return self._aiohttp_session\n\n    async def inlet(\n        self,\n        body: Dict[str, Any],\n        __event_emitter__: Optional[Callable[[Any], Awaitable[None]]] = None,\n        __user__: Optional[Dict[str, Any]] = None,\n    ) -> Dict[str, Any]:\n        \"\"\"Process incoming messages and inject relevant memories into the context\"\"\"\n        self.stored_memories = None\n        self._error_message = None\n\n        if not body or not isinstance(body, dict) or not __user__:\n            logger.debug(\"Missing body or user information in inlet\")\n            return body\n\n        # Check if the function is enabled for this user\n        user_valves = self._get_user_valves(__user__)\n        if not user_valves.enabled:\n            logger.debug(\n                f\"Memory manager disabled for user {__user__.get('id', 'unknown')}\"\n            )\n            return body\n\n        try:\n            if \"messages\" in body and body[\"messages\"]:\n                user_messages = [m for m in body[\"messages\"] if m[\"role\"] == \"user\"]\n                if user_messages:\n                    # Determine if status updates should be shown\n                    show_status = user_valves.show_status\n\n                    # Safely emit status update\n                    if show_status:\n                        await self._safe_emit(\n                            __event_emitter__,\n                            {\n                                \"type\": \"status\",\n                                \"data\": {\n                                    \"description\": \"ðŸ’­ Retrieving relevant memories...\",\n                                    \"done\": False,\n                                },\n                            },\n                        )\n\n                    # Get user timezone if specified\n                    user_timezone = (\n                        user_valves.timezone\n                        if user_valves.timezone\n                        else self.valves.timezone\n                    )\n\n                    # Get relevant memories for the current context\n                    relevant_memories = await self.get_relevant_memories(\n                        user_messages[-1][\"content\"], __user__[\"id\"], user_timezone\n                    )\n\n                    # Safely emit completion status\n                    if show_status:\n                        await self._safe_emit(\n                            __event_emitter__,\n                            {\n                                \"type\": \"status\",\n                                \"data\": {\n                                    \"description\": \"â˜‘ Memory retrieval complete\",\n                                    \"done\": True,\n                                },\n                            },\n                        )\n\n                    # Inject relevant memories into the context if show_memories is enabled\n                    if self.valves.show_memories and relevant_memories:\n                        self._inject_memories_into_context(body, relevant_memories)\n\n        except Exception as e:\n            logger.error(f\"Error in inlet: {e}\\n{traceback.format_exc()}\")\n            await self._safe_emit(\n                __event_emitter__,\n                {\n                    \"type\": \"status\",\n                    \"data\": {\n                        \"description\": f\"ðŸ™ˆ Error retrieving memories: {str(e)}\",\n                        \"done\": True,\n                    },\n                },\n            )\n\n        return body\n\n    async def outlet(\n        self,\n        body: dict,\n        __event_emitter__: Optional[Callable[[Any], Awaitable[None]]] = None,\n        __user__: Optional[dict] = None,\n    ) -> dict:\n        \"\"\"Process outgoing messages for memory operations\"\"\"\n        if not body or not isinstance(body, dict) or not __user__:\n            logger.debug(\"Missing body or user information in outlet\")\n            return body\n\n        # Check if the function is enabled for this user\n        user_valves = self._get_user_valves(__user__)\n        if not user_valves.enabled:\n            logger.debug(\n                f\"Memory manager disabled for user {__user__.get('id', 'unknown')}\"\n            )\n            return body\n\n        try:\n            if \"messages\" in body and len(body[\"messages\"]) >= 2:\n                # Process memory updates BEFORE waiting for the full LLM response\n                memory_task = None\n                user_message = None\n\n                # Get the most recent user message (input to the assistant)\n                user_messages = [m for m in body[\"messages\"] if m[\"role\"] == \"user\"]\n                if user_messages:\n                    user_message = user_messages[-1][\"content\"]\n\n                    # Determine if status updates should be shown\n                    show_status = user_valves.show_status\n\n                    # Get user timezone if specified\n                    user_timezone = (\n                        user_valves.timezone\n                        if user_valves.timezone\n                        else self.valves.timezone\n                    )\n\n                    # Safely emit status update\n                    if show_status:\n                        await self._safe_emit(\n                            __event_emitter__,\n                            {\n                                \"type\": \"status\",\n                                \"data\": {\n                                    \"description\": \"ðŸ’­ Processing memories...\",\n                                    \"done\": False,\n                                },\n                            },\n                        )\n\n                    # Start memory processing early in a background task\n                    memory_task = asyncio.create_task(\n                        self._process_user_memories(\n                            user_message,\n                            __user__[\"id\"],\n                            __event_emitter__,\n                            show_status,\n                            user_timezone,\n                        )\n                    )\n\n                    # Track the task\n                    self._background_tasks.add(memory_task)\n                    memory_task.add_done_callback(self._background_tasks.discard)\n\n                # If we've started memory processing, wait for it to complete\n                if memory_task:\n                    try:\n                        self.stored_memories = await memory_task\n\n                        # Add confirmation message if enabled and operations were performed\n                        if self.valves.show_status and (\n                            self.stored_memories or self._error_message\n                        ):\n                            await self._add_confirmation_message(body)\n                    except asyncio.CancelledError:\n                        logger.debug(\"Memory processing task cancelled\")\n                    except Exception as e:\n                        logger.error(\n                            f\"Error in memory processing task: {e}\\n{traceback.format_exc()}\"\n                        )\n                        if show_status:\n                            await self._safe_emit(\n                                __event_emitter__,\n                                {\n                                    \"type\": \"status\",\n                                    \"data\": {\n                                        \"description\": f\"ðŸ™ˆ Error processing memories: {str(e)}\",\n                                        \"done\": True,\n                                    },\n                                },\n                            )\n\n        except Exception as e:\n            logger.error(f\"Error in outlet: {e}\\n{traceback.format_exc()}\")\n            await self._safe_emit(\n                __event_emitter__,\n                {\n                    \"type\": \"status\",\n                    \"data\": {\n                        \"description\": f\"ðŸ™ˆ Error processing memories: {str(e)}\",\n                        \"done\": True,\n                    },\n                },\n            )\n\n        return body\n\n    async def _safe_emit(\n        self,\n        event_emitter: Optional[Callable[[Any], Awaitable[None]]],\n        data: Dict[str, Any],\n    ) -> None:\n        \"\"\"Safely emit an event, handling missing emitter\"\"\"\n        if not event_emitter:\n            logger.debug(\"Event emitter not available\")\n            return\n\n        try:\n            await event_emitter(data)\n        except Exception as e:\n            logger.error(f\"Error in event emitter: {e}\")\n\n    def _get_user_valves(self, __user__: dict) -> UserValves:\n        \"\"\"Extract and validate user valves settings\"\"\"\n        if not __user__:\n            logger.warning(\"No user information provided\")\n            return self.UserValves()\n\n        user_valves = __user__.get(\"valves\", {})\n\n        # If valves is already a dict, use it directly\n        if isinstance(user_valves, dict):\n            return self.UserValves(**user_valves)\n\n        # If valves is an object, try to convert it\n        try:\n            # If it's already a UserValves object, return it\n            if isinstance(user_valves, self.UserValves):\n                return user_valves\n\n            # Otherwise try to extract attributes\n            return self.UserValves(\n                enabled=getattr(user_valves, \"enabled\", True),\n                show_status=getattr(user_valves, \"show_status\", True),\n                timezone=getattr(user_valves, \"timezone\", \"\"),\n            )\n        except (AttributeError, TypeError):\n            # Default to enabled if extraction fails\n            logger.debug(\"Could not determine user valves settings, using defaults\")\n            return self.UserValves()\n\n    async def _get_formatted_memories(self, user_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all memories for a user and format them for processing\"\"\"\n        memories_list = []\n        try:\n            # Get memories using Memories.get_memories_by_user_id\n            user_memories = Memories.get_memories_by_user_id(user_id=str(user_id))\n\n            if user_memories:\n                for memory in user_memories:\n                    # Safely extract attributes with fallbacks\n                    memory_id = str(getattr(memory, \"id\", \"unknown\"))\n                    memory_content = getattr(memory, \"content\", \"\")\n                    created_at = getattr(memory, \"created_at\", None)\n                    updated_at = getattr(memory, \"updated_at\", None)\n\n                    memories_list.append(\n                        {\n                            \"id\": memory_id,\n                            \"memory\": memory_content,\n                            \"created_at\": created_at,\n                            \"updated_at\": updated_at,\n                        }\n                    )\n\n            logger.debug(f\"Retrieved {len(memories_list)} memories for user {user_id}\")\n            return memories_list\n\n        except Exception as e:\n            logger.error(\n                f\"Error getting formatted memories: {e}\\n{traceback.format_exc()}\"\n            )\n            return []\n\n    def _inject_memories_into_context(\n        self, body: Dict[str, Any], memories: List[Dict[str, Any]]\n    ) -> None:\n        \"\"\"Inject relevant memories into the system context\"\"\"\n        if not memories:\n            return\n\n        # Sort memories by relevance if available\n        sorted_memories = sorted(\n            memories, key=lambda x: x.get(\"relevance\", 0), reverse=True\n        )\n\n        # Format memories based on user preference\n        memory_context = self._format_memories_for_context(\n            sorted_memories, self.valves.memory_format\n        )\n\n        # Add to system message or create a new one if none exists\n        if \"messages\" in body:\n            system_message_exists = False\n            for message in body[\"messages\"]:\n                if message[\"role\"] == \"system\":\n                    message[\"content\"] += f\"\\n\\n{memory_context}\"\n                    system_message_exists = True\n                    break\n\n            if not system_message_exists:\n                body[\"messages\"].insert(\n                    0, {\"role\": \"system\", \"content\": memory_context}\n                )\n\n    def _format_memories_for_context(\n        self, memories: List[Dict[str, Any]], format_type: str\n    ) -> str:\n        \"\"\"Format memories for context injection based on format preference\"\"\"\n        if not memories:\n            return \"\"\n\n        # Start with header\n        memory_context = \"I recall the following about you:\\n\"\n\n        # Extract tags and add each memory according to specified format\n        if format_type == \"bullet\":\n            for mem in memories:\n                tags_match = re.match(r\"\\[Tags: (.*?)\\] (.*)\", mem[\"memory\"])\n                if tags_match:\n                    tags = tags_match.group(1)\n                    content = tags_match.group(2)\n                    memory_context += f\"- {content} (tags: {tags})\\n\"\n                else:\n                    memory_context += f\"- {mem['memory']}\\n\"\n\n        elif format_type == \"numbered\":\n            for i, mem in enumerate(memories, 1):\n                tags_match = re.match(r\"\\[Tags: (.*?)\\] (.*)\", mem[\"memory\"])\n                if tags_match:\n                    tags = tags_match.group(1)\n                    content = tags_match.group(2)\n                    memory_context += f\"{i}. {content} (tags: {tags})\\n\"\n                else:\n                    memory_context += f\"{i}. {mem['memory']}\\n\"\n\n        else:  # paragraph format\n            memories_text = []\n            for mem in memories:\n                tags_match = re.match(r\"\\[Tags: (.*?)\\] (.*)\", mem[\"memory\"])\n                if tags_match:\n                    content = tags_match.group(2)\n                    memories_text.append(content)\n                else:\n                    memories_text.append(mem[\"memory\"])\n\n            memory_context += f\"{'. '.join(memories_text)}.\\n\"\n\n        return memory_context\n\n    async def _process_user_memories(\n        self,\n        user_message: str,\n        user_id: str,\n        __event_emitter__: Optional[Callable[[Any], Awaitable[None]]] = None,\n        show_status: bool = True,\n        user_timezone: str = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Process user message for memory operations\"\"\"\n        logger.debug(f\"Processing memories for message: {user_message[:50]}...\")\n\n        # Get existing memories for context\n        existing_memories = await self._get_formatted_memories(user_id)\n\n        # Identify new memories from user message\n        memories = await self.identify_memories(\n            user_message, existing_memories, user_timezone\n        )\n\n        if memories:\n            logger.info(f\"Found {len(memories)} memory operations to process\")\n            success = await self.process_memories(memories, user_id)\n\n            # Emit completion status\n            if show_status:\n                if success:\n                    await self._safe_emit(\n                        __event_emitter__,\n                        {\n                            \"type\": \"status\",\n                            \"data\": {\n                                \"description\": \"ðŸ§  Memories updated\",\n                                \"done\": True,\n                            },\n                        },\n                    )\n                else:\n                    await self._safe_emit(\n                        __event_emitter__,\n                        {\n                            \"type\": \"status\",\n                            \"data\": {\n                                \"description\": \"ðŸ™ˆ Failed to update memories\",\n                                \"done\": True,\n                            },\n                        },\n                    )\n        else:\n            logger.debug(\"No new memories identified\")\n            # Emit completion status (no new memories found)\n            if show_status:\n                await self._safe_emit(\n                    __event_emitter__,\n                    {\n                        \"type\": \"status\",\n                        \"data\": {\n                            \"description\": \"\",\n                            \"done\": True,\n                        },\n                    },\n                )\n\n        return memories\n\n    async def identify_memories(\n        self,\n        input_text: str,\n        existing_memories: Optional[List[Dict[str, Any]]] = None,\n        user_timezone: str = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Identify memory operations from the input text\"\"\"\n        logger.debug(\"Starting memory identification\")\n        try:\n            # Build the prompt with existing memories for context\n            system_prompt = self.valves.memory_identification_prompt\n\n            # Add category filter configuration\n            category_config = []\n            if self.valves.enable_identity_memories:\n                category_config.append(\n                    \"- Basic Identity information (age, gender, location, etc.)\"\n                )\n            if self.valves.enable_behavior_memories:\n                category_config.append(\n                    \"- Behavior information (interests, habits, etc.)\"\n                )\n            if self.valves.enable_preference_memories:\n                category_config.append(\n                    \"- Preference information (likes, dislikes, etc.)\"\n                )\n            if self.valves.enable_goal_memories:\n                category_config.append(\n                    \"- Goal information (aspirations, targets, etc.)\"\n                )\n            if self.valves.enable_relationship_memories:\n                category_config.append(\n                    \"- Relationship information (friends, family, etc.)\"\n                )\n            if self.valves.enable_possession_memories:\n                category_config.append(\n                    \"- Possession information (things owned or desired)\"\n                )\n\n            if category_config:\n                system_prompt += \"\\n\\nCurrently configured to collect ONLY these categories of information:\\n\"\n                system_prompt += \"\\n\".join(category_config)\n\n            if existing_memories:\n                memory_strings = []\n                for mem in existing_memories:\n                    memory_strings.append(f\"ID: {mem['id']}, CONTENT: {mem['memory']}\")\n\n                system_prompt += f\"\\n\\nExisting memories:\\n{json.dumps(memory_strings)}\"\n\n            # Get the current date and time for context\n            current_datetime = self.get_formatted_datetime(user_timezone)\n\n            # Add current datetime for context with more detail\n            system_prompt += f\"\"\"\nCurrent datetime information:\n- Date: {current_datetime.strftime('%Y-%m-%d')}\n- Time: {current_datetime.strftime('%H:%M:%S')}\n- Day of week: {current_datetime.strftime('%A')}\n- Month: {current_datetime.strftime('%B')}\n- Year: {current_datetime.strftime('%Y')}\n- Timezone: {current_datetime.tzinfo}\n\"\"\"\n\n            # Add important reminder about JSON format\n            system_prompt += \"\"\"\nVERY IMPORTANT: Your response must be a valid JSON array like this:\n[{\"operation\": \"NEW\", \"content\": \"User likes coffee\", \"tags\": [\"preference\"]}]\n\nDo not format your response like this (this is invalid):\n[\"NEW\", \"id\": \"123\", \"content\": \"User likes coffee\", \"tags\": [\"preference\"]]\n\"\"\"\n\n            # Query the LLM with retries\n            response = await self.query_llm_with_retry(system_prompt, input_text)\n\n            if not response or response.startswith(\"Error:\"):\n                if response:\n                    self._error_message = response\n                    logger.error(f\"Error from LLM: {response}\")\n                return []\n\n            # Log the raw response for debugging\n            logger.debug(f\"Raw LLM response: {response[:500]}\")\n\n            # Extract and parse JSON\n            memory_operations = self._extract_and_parse_json(response)\n\n            if memory_operations is None:\n                logger.warning(\"Failed to parse any valid JSON from LLM response\")\n                return []\n\n            if not isinstance(memory_operations, list):\n                logger.warning(\n                    f\"Invalid memory operations format (not a list): {memory_operations}\"\n                )\n                return []\n\n            # Validate the operations\n            valid_operations = []\n            existing_ids = (\n                {mem[\"id\"] for mem in existing_memories} if existing_memories else set()\n            )\n\n            for op in memory_operations:\n                try:\n                    # Attempt to fix and validate the operation\n                    if self._validate_memory_operation(op):\n                        # Validate IDs for UPDATE/DELETE operations\n                        if op[\"operation\"] in [\"UPDATE\", \"DELETE\"]:\n                            if op[\"id\"] not in existing_ids:\n                                logger.warning(\n                                    f\"Invalid memory ID for {op['operation']}: {op['id']}\"\n                                )\n                                continue\n                        valid_operations.append(op)\n                    else:\n                        logger.warning(f\"Invalid memory operation format: {op}\")\n                except Exception as e:\n                    logger.warning(f\"Error validating memory operation: {e}, op: {op}\")\n\n            logger.info(f\"Identified {len(valid_operations)} valid memory operations\")\n            return valid_operations\n\n        except Exception as e:\n            logger.error(f\"Error identifying memories: {e}\\n{traceback.format_exc()}\")\n            return []\n\n    def _validate_memory_operation(self, op: Dict[str, Any]) -> bool:\n        \"\"\"Validate memory operation format and required fields\"\"\"\n        if not isinstance(op, dict):\n            logger.warning(f\"Invalid memory operation format (not a dict): {op}\")\n            return False\n\n        # Check if operation field exists, if not try to infer it\n        if \"operation\" not in op:\n            # Look for typical patterns to guess the operation type\n            if any(k.lower() == \"operation\" for k in op.keys()):\n                # Operation may be under a different case\n                for k, v in op.items():\n                    if k.lower() == \"operation\" and isinstance(v, str):\n                        op[\"operation\"] = v\n                        break\n\n            # Look for operation in original format but in wrong place\n            elif isinstance(op, dict) and any(\n                v in [\"NEW\", \"UPDATE\", \"DELETE\"] for v in op.values()\n            ):\n                for k, v in op.items():\n                    if v in [\"NEW\", \"UPDATE\", \"DELETE\"]:\n                        op[\"operation\"] = v\n                        # Remove the old key if it's not \"operation\"\n                        if k != \"operation\":\n                            op.pop(k, None)\n                        break\n\n            # Default based on presence of fields\n            elif \"id\" in op and \"content\" in op:\n                # Default to UPDATE if we have both id and content\n                op[\"operation\"] = \"UPDATE\"\n            elif \"content\" in op:\n                # Default to NEW if we only have content\n                op[\"operation\"] = \"NEW\"\n            else:\n                logger.warning(f\"Cannot determine operation type for: {op}\")\n                return False\n\n        # Normalize operation to uppercase\n        if isinstance(op[\"operation\"], str):\n            op[\"operation\"] = op[\"operation\"].upper()\n\n        if op[\"operation\"] not in [\"NEW\", \"UPDATE\", \"DELETE\"]:\n            logger.warning(f\"Invalid operation type: {op['operation']}\")\n            return False\n\n        if op[\"operation\"] in [\"UPDATE\", \"DELETE\"] and \"id\" not in op:\n            logger.warning(f\"Missing ID for {op['operation']} operation: {op}\")\n            return False\n\n        if op[\"operation\"] in [\"NEW\", \"UPDATE\"] and \"content\" not in op:\n            logger.warning(f\"Missing content for {op['operation']} operation: {op}\")\n            return False\n\n        # Tags are optional but should be a list if present\n        if \"tags\" in op and not isinstance(op[\"tags\"], list):\n            # Try to fix if it's a string\n            if isinstance(op[\"tags\"], str):\n                try:\n                    # See if it's a JSON string\n                    parsed_tags = json.loads(op[\"tags\"])\n                    if isinstance(parsed_tags, list):\n                        op[\"tags\"] = parsed_tags\n                    else:\n                        # If it parsed but isn't a list, handle that case\n                        op[\"tags\"] = [str(parsed_tags)]\n                except json.JSONDecodeError:\n                    # Split by comma if it looks like a comma-separated list\n                    if \",\" in op[\"tags\"]:\n                        op[\"tags\"] = [tag.strip() for tag in op[\"tags\"].split(\",\")]\n                    else:\n                        # Just make it a single-item list\n                        op[\"tags\"] = [op[\"tags\"]]\n            else:\n                logger.warning(\n                    f\"Invalid tags format, not a list or string: {op['tags']}\"\n                )\n                op[\"tags\"] = []  # Default to empty list\n\n        return True\n\n    async def _extract_and_parse_json(self, text: str) -> Union[List, Dict, None]:\n        \"\"\"Extract and parse JSON from text, handling common LLM response issues\"\"\"\n        if not text:\n            logger.warning(\"Empty text provided to JSON parser\")\n            return None\n\n        # Check if text is already a dict/list (already parsed JSON)\n        if isinstance(text, (dict, list)):\n            return text\n\n        # Clean the text\n        text = text.strip()\n\n        # Try direct parsing first (most efficient if valid)\n        try:\n            parsed = json.loads(text)\n            logger.debug(\"Successfully parsed JSON directly\")\n            return parsed\n        except json.JSONDecodeError:\n            pass\n\n        # Handle special case seen in logs: [\"NEW\", \"id\": \"9e4d6c2b-...\", \"content\": \"...\", \"tags\": [...] ]\n        malformed_pattern = r'\\[\"(NEW|UPDATE|DELETE)\"(?:\\s*,\\s*|)(?:\"id\":|)\"([^\"]*)\"(?:\\s*,\\s*|)(?:\"content\":|)\"([^\"]*)\"(?:\\s*,\\s*|)(?:\"tags\":|)(\\[[^\\]]*\\])'\n        match = re.search(malformed_pattern, text, re.DOTALL | re.IGNORECASE)\n        if match:\n            try:\n                operation = match.group(1).upper()\n                id_value = match.group(2).strip() if match.group(2) else None\n                content = match.group(3).strip()\n                tags_str = match.group(4).strip()\n\n                try:\n                    tags = json.loads(tags_str)\n                except json.JSONDecodeError:\n                    # If tags can't be parsed, default to empty list\n                    tags = []\n\n                memory_op = {\"operation\": operation, \"content\": content, \"tags\": tags}\n                if id_value:\n                    memory_op[\"id\"] = id_value\n\n                logger.debug(\n                    f\"Successfully parsed malformed JSON using pattern: {memory_op}\"\n                )\n                return [memory_op]\n            except Exception as e:\n                logger.warning(f\"Failed to fix malformed JSON with pattern: {e}\")\n\n        # Try to find JSON array using regex (more robust approach)\n        json_array_pattern = r\"\\[\\s*\\{.*?\\}\\s*(?:,\\s*\\{.*?\\}\\s*)*\\]\"\n        array_match = re.search(json_array_pattern, text, re.DOTALL)\n\n        if array_match:\n            json_text = array_match.group(0)\n            try:\n                parsed = json.loads(json_text)\n                logger.debug(\"Successfully parsed JSON array using regex\")\n                return parsed\n            except json.JSONDecodeError:\n                logger.debug(\"Found JSON-like array but couldn't parse it\")\n\n        # Try to find JSON objects one by one\n        json_object_pattern = r'\\{\\s*\"operation\"\\s*:\\s*\"(NEW|UPDATE|DELETE)\".*?\\}'\n        object_matches = re.finditer(\n            json_object_pattern, text, re.DOTALL | re.IGNORECASE\n        )\n\n        operations = []\n        for match in object_matches:\n            try:\n                obj = json.loads(match.group(0))\n                operations.append(obj)\n            except json.JSONDecodeError:\n                continue\n\n        if operations:\n            logger.debug(\n                f\"Successfully extracted {len(operations)} operations from text\"\n            )\n            return operations\n\n        # Try extracting from code blocks\n        code_block_pattern = r\"```(?:json)?(.*?)```\"\n        code_blocks = re.findall(code_block_pattern, text, re.DOTALL)\n\n        if code_blocks:\n            for block in code_blocks:\n                try:\n                    parsed = json.loads(block.strip())\n                    logger.debug(\"Successfully parsed JSON from code block\")\n                    return parsed\n                except json.JSONDecodeError:\n                    continue\n\n        # Last resort: Try to extract key-value pairs directly\n        # This handles cases like: ID: abc123, OPERATION: NEW, CONTENT: User likes coffee\n        if \"ID:\" in text and (\"OPERATION:\" in text or \"CONTENT:\" in text):\n            try:\n                operations = []\n                # Extract memory entries with regex\n                memory_pattern = r\"ID:\\s*([^,\\n]+)(?:,\\s*OPERATION:\\s*([^,\\n]+))?,\\s*(?:ID:\\s*([^,\\n]+),\\s*)?CONTENT:\\s*([^\\n]+)\"\n                matches = re.findall(memory_pattern, text, re.IGNORECASE | re.DOTALL)\n\n                for match in matches:\n                    mem_id = match[0].strip()\n                    operation = match[1].strip().upper() if match[1] else \"UPDATE\"\n                    content_id = match[2].strip() if match[2] else mem_id\n                    content = match[3].strip()\n\n                    operations.append(\n                        {\n                            \"operation\": operation,\n                            \"id\": content_id,\n                            \"content\": content,\n                            \"tags\": [],\n                        }\n                    )\n\n                if operations:\n                    logger.debug(\n                        f\"Successfully extracted {len(operations)} operations using key-value pattern\"\n                    )\n                    return operations\n            except Exception as e:\n                logger.debug(f\"Failed manual JSON construction: {e}\")\n\n        logger.warning(f\"Failed to parse JSON from text: {text[:200]}...\")\n        return None\n\n    def _calculate_memory_similarity(self, memory1: str, memory2: str) -> float:\n        \"\"\"\n        Calculate similarity between two memory contents using a more robust method.\n        Returns a score between 0.0 (completely different) and 1.0 (identical).\n        \"\"\"\n        if not memory1 or not memory2:\n            return 0.0\n\n        # Clean the memories - remove tags and normalize\n        memory1_clean = re.sub(r\"\\[Tags:.*?\\]\\s*\", \"\", memory1).lower().strip()\n        memory2_clean = re.sub(r\"\\[Tags:.*?\\]\\s*\", \"\", memory2).lower().strip()\n\n        # Handle exact matches quickly\n        if memory1_clean == memory2_clean:\n            return 1.0\n\n        # Handle near-duplicates with same meaning but minor differences\n        # Split into words and compare overlap\n        words1 = set(re.findall(r\"\\b\\w+\\b\", memory1_clean))\n        words2 = set(re.findall(r\"\\b\\w+\\b\", memory2_clean))\n\n        if not words1 or not words2:\n            return 0.0\n\n        # Calculate Jaccard similarity for word overlap\n        intersection = len(words1.intersection(words2))\n        union = len(words1.union(words2))\n        jaccard = intersection / union if union > 0 else 0.0\n\n        # Use sequence matcher for more precise comparison\n        seq_similarity = SequenceMatcher(None, memory1_clean, memory2_clean).ratio()\n\n        # Combine both metrics, weighting sequence similarity higher\n        combined_similarity = (0.4 * jaccard) + (0.6 * seq_similarity)\n\n        return combined_similarity\n\n    async def get_relevant_memories(\n        self, current_message: str, user_id: str, user_timezone: str = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Get memories relevant to the current context\"\"\"\n        try:\n            # Get all memories for the user\n            existing_memories = await self._get_formatted_memories(user_id)\n\n            if not existing_memories:\n                logger.debug(\"No existing memories found for relevance assessment\")\n                return []\n\n            # Build the prompt\n            memory_strings = []\n            for mem in existing_memories:\n                memory_strings.append(f\"ID: {mem['id']}, CONTENT: {mem['memory']}\")\n\n            system_prompt = self.valves.memory_relevance_prompt\n            user_prompt = f\"\"\"Current user message: \"{current_message}\"\n\nAvailable memories:\n{json.dumps(memory_strings)}\n\nRate the relevance of each memory to the current user message.\"\"\"\n\n            # Add current datetime for context\n            current_datetime = self.get_formatted_datetime(user_timezone)\n            user_prompt += f\"\"\"\n\nCurrent datetime: {current_datetime.strftime('%A, %B %d, %Y %H:%M:%S')} ({current_datetime.tzinfo})\"\"\"\n\n            # Query the LLM with retries\n            response = await self.query_llm_with_retry(system_prompt, user_prompt)\n\n            if not response or response.startswith(\"Error:\"):\n                if response:\n                    logger.error(f\"Error from LLM during memory relevance: {response}\")\n                return []\n\n            # Extract and parse JSON\n            relevance_data = self._extract_and_parse_json(response)\n\n            if not relevance_data:\n                logger.warning(\"Failed to parse relevance data from LLM response\")\n                return []\n\n            if not isinstance(relevance_data, list):\n                logger.warning(\n                    f\"Invalid relevance data format (not a list): {relevance_data}\"\n                )\n                return []\n\n            # Filter by relevance threshold and sort by relevance\n            relevant_memories = []\n            threshold = self.valves.relevance_threshold\n\n            for item in relevance_data:\n                if not isinstance(item, dict):\n                    logger.warning(\n                        f\"Invalid item in relevance data (not a dict): {item}\"\n                    )\n                    continue\n\n                # Check for different key patterns (handle inconsistent LLM outputs)\n                memory = item.get(\"memory\")\n                if memory is None:\n                    for key in item.keys():\n                        if \"memory\" in key.lower() or \"content\" in key.lower():\n                            memory = item[key]\n                            break\n\n                relevance = item.get(\"relevance\")\n                if relevance is None:\n                    for key in item.keys():\n                        if \"relevance\" in key.lower() or \"score\" in key.lower():\n                            try:\n                                relevance = float(item[key])\n                            except (ValueError, TypeError):\n                                relevance = None\n                            break\n\n                id_val = item.get(\"id\")\n                if id_val is None:\n                    for key in item.keys():\n                        if key.lower() == \"id\" or \"identifier\" in key.lower():\n                            id_val = item[key]\n                            break\n\n                # Validate we have all required fields\n                if memory and isinstance(relevance, (int, float)) and id_val:\n                    if relevance >= threshold:\n                        memory_dict = {\n                            \"id\": id_val,\n                            \"memory\": memory,\n                            \"relevance\": relevance,\n                        }\n                        relevant_memories.append(memory_dict)\n\n            # Sort by relevance (descending)\n            relevant_memories.sort(key=lambda x: x[\"relevance\"], reverse=True)\n\n            # Limit to configured number\n            logger.info(\n                f\"Found {len(relevant_memories)} relevant memories above threshold {threshold}\"\n            )\n            return relevant_memories[: self.valves.related_memories_n]\n\n        except Exception as e:\n            logger.error(\n                f\"Error getting relevant memories: {e}\\n{traceback.format_exc()}\"\n            )\n            return []\n\n    async def process_memories(\n        self, memories: List[Dict[str, Any]], user_id: str\n    ) -> bool:\n        \"\"\"Process memory operations\"\"\"\n        try:\n            user = Users.get_user_by_id(user_id)\n            if not user:\n                logger.error(f\"User not found: {user_id}\")\n                return False\n\n            # Get existing memories for deduplication\n            existing_memories = []\n            if self.valves.deduplicate_memories:\n                existing_memories = await self._get_formatted_memories(user_id)\n\n            logger.debug(f\"Processing {len(memories)} memory operations\")\n\n            # First filter for duplicates if enabled\n            processed_memories = []\n            if self.valves.deduplicate_memories and existing_memories:\n                # Store all existing contents for quick lookup\n                existing_contents = []\n                for mem in existing_memories:\n                    existing_contents.append(mem[\"memory\"])\n\n                # Check each new memory against existing ones\n                for memory_dict in memories:\n                    if memory_dict[\"operation\"] == \"NEW\":\n                        # Format the memory content\n                        operation = MemoryOperation(**memory_dict)\n                        formatted_content = self._format_memory_content(operation)\n\n                        # Check for similarity with existing memories\n                        is_duplicate = False\n                        for existing_content in existing_contents:\n                            similarity = self._calculate_memory_similarity(\n                                formatted_content, existing_content\n                            )\n                            if similarity >= self.valves.similarity_threshold:\n                                logger.debug(\n                                    f\"Skipping duplicate memory (similarity: {similarity:.2f}): {formatted_content[:50]}...\"\n                                )\n                                is_duplicate = True\n                                break\n\n                        if not is_duplicate:\n                            processed_memories.append(memory_dict)\n                    else:\n                        # Keep all UPDATE and DELETE operations\n                        processed_memories.append(memory_dict)\n            else:\n                processed_memories = memories\n\n            # Process the filtered memories\n            for memory_dict in processed_memories:\n                try:\n                    # Validate memory operation\n                    operation = MemoryOperation(**memory_dict)\n                    # Execute the memory operation\n                    await self._execute_memory_operation(operation, user)\n                except ValueError as e:\n                    logger.error(f\"Invalid memory operation: {e} {memory_dict}\")\n                    continue\n                except Exception as e:\n                    logger.error(f\"Error executing memory operation: {e} {memory_dict}\")\n                    continue\n\n            logger.info(\n                f\"Successfully processed {len(processed_memories)} memory operations\"\n            )\n            return True\n        except Exception as e:\n            logger.error(f\"Error processing memories: {e}\\n{traceback.format_exc()}\")\n            return False\n\n    async def _execute_memory_operation(\n        self, operation: MemoryOperation, user: Any\n    ) -> None:\n        \"\"\"Execute a memory operation (NEW, UPDATE, DELETE)\"\"\"\n        formatted_content = self._format_memory_content(operation)\n\n        if operation.operation == \"NEW\":\n            try:\n                result = await add_memory(\n                    request=Request(scope={\"type\": \"http\", \"app\": webui_app}),\n                    form_data=AddMemoryForm(content=formatted_content),\n                    user=user,\n                )\n                logger.info(f\"NEW memory created: {formatted_content[:50]}...\")\n            except Exception as e:\n                logger.error(f\"Error creating memory: {e}\\n{traceback.format_exc()}\")\n                raise\n\n        elif operation.operation == \"UPDATE\" and operation.id:\n            try:\n                # Delete existing memory\n                deleted = await delete_memory_by_id(operation.id, user=user)\n                if deleted:\n                    # Create new memory with updated content\n                    result = await add_memory(\n                        request=Request(scope={\"type\": \"http\", \"app\": webui_app}),\n                        form_data=AddMemoryForm(content=formatted_content),\n                        user=user,\n                    )\n                    logger.info(\n                        f\"UPDATE memory {operation.id}: {formatted_content[:50]}...\"\n                    )\n                else:\n                    logger.warning(f\"Memory {operation.id} not found for UPDATE\")\n            except Exception as e:\n                logger.error(f\"Error updating memory: {e}\\n{traceback.format_exc()}\")\n                raise\n\n        elif operation.operation == \"DELETE\" and operation.id:\n            try:\n                deleted = await delete_memory_by_id(operation.id, user=user)\n                logger.info(f\"DELETE memory {operation.id}: {deleted}\")\n            except Exception as e:\n                logger.error(f\"Error deleting memory: {e}\\n{traceback.format_exc()}\")\n                raise\n\n    def _format_memory_content(self, operation: MemoryOperation) -> str:\n        \"\"\"Format memory content with tags\"\"\"\n        if not operation.tags:\n            return operation.content or \"\"\n\n        return f\"[Tags: {', '.join(operation.tags)}] {operation.content}\"\n\n    async def query_llm_with_retry(self, system_prompt: str, user_prompt: str) -> str:\n        \"\"\"Query LLM with retry logic\"\"\"\n        max_retries = self.valves.max_retries\n        retry_delay = self.valves.retry_delay\n        attempt = 0\n\n        while attempt <= max_retries:\n            try:\n                # Increment attempt counter\n                attempt += 1\n\n                # Validate API configuration\n                if self.valves.api_provider == \"Ollama API\":\n                    if not self.valves.ollama_api_url:\n                        return \"Error: Ollama API URL not configured\"\n                    if not self.valves.ollama_model:\n                        return \"Error: Ollama model not configured\"\n                elif self.valves.api_provider == \"OpenAI API\":\n                    if not self.valves.openai_api_url:\n                        return \"Error: OpenAI API URL not configured\"\n                    if not self.valves.openai_api_key:\n                        return \"Error: OpenAI API key not configured\"\n                    if not self.valves.openai_model:\n                        return \"Error: OpenAI model not configured\"\n                else:\n                    return f\"Error: Unknown API provider {self.valves.api_provider}\"\n\n                # Make the API call based on provider\n                if self.valves.api_provider == \"Ollama API\":\n                    response = await self._query_ollama(\n                        model=self.valves.ollama_model,\n                        system_prompt=system_prompt,\n                        user_prompt=user_prompt,\n                    )\n                elif self.valves.api_provider == \"OpenAI API\":\n                    response = await self._query_openai(\n                        model=self.valves.openai_model,\n                        system_prompt=system_prompt,\n                        user_prompt=user_prompt,\n                    )\n\n                # Check if the response indicates an error that should be retried\n                if response.startswith(\"Error:\") and \"timeout\" in response.lower():\n                    logger.warning(\n                        f\"Timeout error on attempt {attempt}, will retry: {response}\"\n                    )\n                    if attempt <= max_retries:\n                        await asyncio.sleep(\n                            retry_delay * attempt\n                        )  # Exponential backoff\n                        continue\n\n                # If we got a valid response or a non-retryable error, return it\n                return response\n\n            except Exception as e:\n                logger.error(f\"Error on attempt {attempt} when querying LLM: {e}\")\n                if attempt <= max_retries:\n                    await asyncio.sleep(retry_delay * attempt)  # Exponential backoff\n                else:\n                    return f\"Error: Failed after {max_retries} attempts: {str(e)}\"\n\n        # Should never reach here, but just in case\n        return f\"Error: Failed after {max_retries} attempts\"\n\n    async def _query_ollama(\n        self, model: str, system_prompt: str, user_prompt: str\n    ) -> str:\n        \"\"\"Query Ollama API\"\"\"\n        session = await self._get_aiohttp_session()\n        url = f\"{self.valves.ollama_api_url.rstrip('/')}/api/chat\"\n\n        # Validate model availability if we've discovered models\n        if self.available_ollama_models and model not in self.available_ollama_models:\n            model_suggestion = \"\"\n            if self.available_ollama_models:\n                model_suggestion = (\n                    f\" Available models: {', '.join(self.available_ollama_models[:5])}\"\n                )\n                if len(self.available_ollama_models) > 5:\n                    model_suggestion += (\n                        f\" and {len(self.available_ollama_models) - 5} more\"\n                    )\n            logger.warning(\n                f\"Model '{model}' not found in available Ollama models.{model_suggestion}\"\n            )\n\n        # Make sure model has current date awareness\n        date_context = f\"\\nToday's date is {self.date_info['weekday']}, {self.date_info['month']} {self.date_info['day']}, {self.date_info['year']}. Current time is {self.date_info['iso_time']}.\"\n        enhanced_system_prompt = system_prompt + date_context\n\n        payload = {\n            \"model\": model,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": enhanced_system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt},\n            ],\n            \"stream\": False,\n            \"options\": {\n                \"temperature\": 0.1  # Lower temperature for more deterministic outputs\n            },\n        }\n\n        try:\n            async with session.post(url, json=payload, timeout=30) as response:\n                if response.status != 200:\n                    error_text = await response.text()\n                    return f\"Error: Ollama API returned {response.status}: {error_text}\"\n\n                data = await response.json()\n                if \"message\" in data and \"content\" in data[\"message\"]:\n                    return data[\"message\"][\"content\"]\n                else:\n                    return f\"Error: Unexpected Ollama API response format: {data}\"\n        except asyncio.TimeoutError:\n            return \"Error: Ollama API request timed out\"\n        except ClientError as e:\n            return f\"Error: Ollama API connection error: {str(e)}\"\n        except Exception as e:\n            return f\"Error: Ollama API error: {str(e)}\"\n\n    async def _query_openai(\n        self, model: str, system_prompt: str, user_prompt: str\n    ) -> str:\n        \"\"\"Query OpenAI API\"\"\"\n        session = await self._get_aiohttp_session()\n        url = f\"{self.valves.openai_api_url.rstrip('/')}/chat/completions\"\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.valves.openai_api_key}\",\n        }\n\n        # Validate model availability if we've discovered models\n        if self.available_openai_models and model not in self.available_openai_models:\n            model_suggestion = \"\"\n            if self.available_openai_models:\n                model_suggestion = (\n                    f\" Available models: {', '.join(self.available_openai_models[:5])}\"\n                )\n                if len(self.available_openai_models) > 5:\n                    model_suggestion += (\n                        f\" and {len(self.available_openai_models) - 5} more\"\n                    )\n            logger.warning(\n                f\"Model '{model}' not found in available OpenAI models.{model_suggestion}\"\n            )\n\n        # Make sure model has current date awareness\n        date_context = f\"\\nToday's date is {self.date_info['weekday']}, {self.date_info['month']} {self.date_info['day']}, {self.date_info['year']}. Current time is {self.date_info['iso_time']}.\"\n        enhanced_system_prompt = system_prompt + date_context\n\n        payload = {\n            \"model\": model,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": enhanced_system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt},\n            ],\n            \"temperature\": 0.1,  # Lower temperature for more deterministic outputs\n        }\n\n        try:\n            async with session.post(\n                url, headers=headers, json=payload, timeout=30\n            ) as response:\n                if response.status != 200:\n                    error_text = await response.text()\n                    return f\"Error: OpenAI API returned {response.status}: {error_text}\"\n\n                data = await response.json()\n                if (\n                    \"choices\" in data\n                    and len(data[\"choices\"]) > 0\n                    and \"message\" in data[\"choices\"][0]\n                ):\n                    return data[\"choices\"][0][\"message\"][\"content\"]\n                else:\n                    return f\"Error: Unexpected OpenAI API response format: {data}\"\n        except asyncio.TimeoutError:\n            return \"Error: OpenAI API request timed out\"\n        except ClientError as e:\n            return f\"Error: OpenAI API connection error: {str(e)}\"\n        except Exception as e:\n            return f\"Error: OpenAI API error: {str(e)}\"\n\n    async def _add_confirmation_message(self, body: Dict[str, Any]) -> None:\n        \"\"\"Add a confirmation message about memory operations\"\"\"\n        if (\n            not body\n            or \"messages\" not in body\n            or not body[\"messages\"]\n            or not self.valves.show_status\n        ):\n            return\n\n        confirmation = \"\"\n\n        if self._error_message:\n            confirmation = f\"(Memory error: {self._error_message})\"\n        elif self.stored_memories:\n            # Count operations by type\n            new_count = 0\n            update_count = 0\n            delete_count = 0\n\n            for memory in self.stored_memories:\n                if memory[\"operation\"] == \"NEW\":\n                    new_count += 1\n                elif memory[\"operation\"] == \"UPDATE\":\n                    update_count += 1\n                elif memory[\"operation\"] == \"DELETE\":\n                    delete_count += 1\n\n            # Only create a confirmation if operations were performed\n            if new_count > 0 or update_count > 0 or delete_count > 0:\n                # Generate a natural-sounding confirmation message\n                parts = []\n\n                if new_count > 0:\n                    parts.append(\n                        f\"added {new_count} memor{'y' if new_count == 1 else 'ies'}\"\n                    )\n\n                if update_count > 0:\n                    parts.append(\n                        f\"updated {update_count} memor{'y' if update_count == 1 else 'ies'}\"\n                    )\n\n                if delete_count > 0:\n                    parts.append(\n                        f\"deleted {delete_count} memor{'y' if delete_count == 1 else 'ies'}\"\n                    )\n\n                if parts:\n                    if len(parts) == 1:\n                        confirmation = f\"(I've {parts[0]})\"\n                    elif len(parts) == 2:\n                        confirmation = f\"(I've {parts[0]} and {parts[1]})\"\n                    else:\n                        confirmation = (\n                            f\"(I've {', '.join(parts[:-1])}, and {parts[-1]})\"\n                        )\n\n        if confirmation:\n            # Find the last assistant message and append the confirmation\n            for i in reversed(range(len(body[\"messages\"]))):\n                if body[\"messages\"][i][\"role\"] == \"assistant\":\n                    body[\"messages\"][i][\"content\"] += f\" {confirmation}\"\n                    break\n\n    # Cleanup method for aiohttp session and background tasks\n    async def cleanup(self):\n        \"\"\"Clean up resources on shutdown\"\"\"\n        logger.info(\"Performing cleanup of Intelligent Memory Manager resources\")\n\n        # Cancel all background tasks\n        for task in self._background_tasks:\n            if not task.done():\n                task.cancel()\n                try:\n                    # Wait briefly for task to cancel\n                    await asyncio.wait_for(task, timeout=1.0)\n                except (asyncio.TimeoutError, asyncio.CancelledError):\n                    pass\n\n        # Close aiohttp session\n        if self._aiohttp_session and not self._aiohttp_session.closed:\n            await self._aiohttp_session.close()\n            self._aiohttp_session = None\n\n        logger.info(\"Cleanup completed\")\n","meta":{"description":"brain function","manifest":{"title":"Neural Recall","author":"jbuch","author_url":"https://forms.gle/rYoVzRSMeM2azt1F8","funding_url":"https://tiptopjar.com/jbuch","description":"Neural Recall is an advanced memory augmentation system designed to enhance the contextual awareness","version":"1.2.0","license":"MIT"}},"is_active":false,"is_global":false,"updated_at":1748983541,"created_at":1748983541}]